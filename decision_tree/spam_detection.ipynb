{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/spam.csv', encoding='latin-1')\n",
    "df = df.loc[:,['v1','v2']]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'spam':1,'ham':0}\n",
    "df.v1 = list(map(lambda x:d[x],df.v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Text To Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class stemmed_tfidf():\n",
    "    def __init__(self,max_features=5000):\n",
    "        self.ps = PorterStemmer()\n",
    "        self.vc = TfidfVectorizer(analyzer='word',#{‘word’, ‘char’}  Whether the feature should be made of word or character n-grams\n",
    "                             stop_words = 'english',\n",
    "                             max_features = max_features)\n",
    "    def tfidf(self,ListStr):\n",
    "        '''\n",
    "        return: sklearn.feature_extraction.text.TfidfVectorizer\n",
    "        '''\n",
    "        table = self.vc.fit_transform([self.stem_string(s) for s in ListStr])\n",
    "        return table\n",
    "    def stem_string(self,s):\n",
    "        '''\n",
    "        s:str, e.g. s = \"Get strings with string. With. Punctuation?\"\n",
    "        ps: stemmer from nltk module\n",
    "        return: bag of words.e.g. 'get string with string with punctuat'\n",
    "        '''    \n",
    "        s = re.sub(r'[^\\w\\s]',' ',s)# remove punctuation.\n",
    "        tokens = word_tokenize(s) # list of words.\n",
    "        #a = [w for w in tokens if not w in stopwords.words('english')]# remove common no meaning words\n",
    "        return ' '.join([self.ps.stem(w) for w in tokens])# e.g. 'desks'->'desk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stf = stemmed_tfidf(max_features=10000)\n",
    "feature = stf.tfidf(df.v2) # this will be a sparse matrix of size (n,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1796)\t0.30434679674817583\n",
      "  (0, 6694)\t0.29053191490659164\n",
      "  (0, 5747)\t0.28073010025130146\n",
      "  (0, 5841)\t0.2531003365681329\n",
      "  (0, 4457)\t0.16689339663532266\n",
      "  (0, 5975)\t0.3163271775444133\n",
      "  (0, 1241)\t0.17740612183932283\n",
      "  (0, 6810)\t0.20143581358576368\n",
      "  (0, 5468)\t0.23143112388098888\n",
      "  (0, 6730)\t0.4423225846361562\n",
      "  (0, 4214)\t0.16659320358399735\n",
      "  (0, 3240)\t0.15141136571437888\n",
      "  (0, 1891)\t0.18321007649041401\n",
      "  (0, 350)\t0.18225024707750948\n",
      "  (0, 6238)\t0.2918822636605647\n",
      "  (0, 3071)\t0.16812133821189043\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "x dimension: 7110\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(feature, df.v1, test_size=0.2, random_state=1)\n",
    "print(Xtest[4])\n",
    "# print(ytest.to_list())\n",
    "\n",
    "def write_to_file(x, y, instance_num=10, file_path=\"../datasets/test/test.data1\"):\n",
    "    assert(len(x) >= instance_num and len(x) == len(y))\n",
    "    x_slice, y_slice = x[:instance_num], y[:instance_num]\n",
    "    print(x_slice)\n",
    "    print(f\"x dimension: {len(x[0])}\")\n",
    "    print(y_slice)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        # write header\n",
    "        features = list(range(len(x[0])))\n",
    "        feature_name = \",\".join([str(c) for c in features])\n",
    "        f.write(f\"label, {feature_name}\\n\")\n",
    "\n",
    "        # write data\n",
    "        for i in range(instance_num):\n",
    "            data_features = \",\".join([str(c) for c in x_slice[i]])\n",
    "            f.write(f\"{y_slice[i]},{data_features}\\n\")\n",
    "    f.close()\n",
    "\n",
    "write_to_file(Xtest.toarray(), ytest.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc = {}\n",
    "F1score = {}\n",
    "confusion_mat={}\n",
    "predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select training parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "The best scores happens on: [[ 2.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [11.]\n",
      " [12.]\n",
      " [13.]\n",
      " [14.]\n",
      " [15.]\n",
      " [16.]\n",
      " [17.]\n",
      " [18.]\n",
      " [19.]\n",
      " [20.]] , where F1 = [0.68825422 0.68825422 0.68825422 0.68825422 0.68825422 0.68825422\n",
      " 0.68825422 0.68825422 0.68825422 0.68825422 0.68825422 0.68825422\n",
      " 0.68825422 0.68825422 0.68825422 0.68825422 0.68825422 0.68825422\n",
      " 0.68825422]\n"
     ]
    }
   ],
   "source": [
    "val_scores = []\n",
    "for i in range(2,21):\n",
    "    DT = DecisionTreeClassifier(min_samples_split=i, max_depth=5, random_state=1,class_weight='balanced')\n",
    "    scores = cross_val_score(DT, Xtrain, ytrain,scoring='f1')\n",
    "    val_scores.append([np.mean(scores),i])\n",
    "print(val_scores.index(max(val_scores)))\n",
    "val_scores = np.array(val_scores)\n",
    "print('The best scores happens on:',val_scores[val_scores[:,0]==max(val_scores[:,0]),1:],\n",
    "      ', where F1 =',val_scores[val_scores[:,0]==max(val_scores[:,0]),0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: Accuracy=0.935, F1=0.714\n"
     ]
    }
   ],
   "source": [
    "name = 'DT'\n",
    "DT = DecisionTreeClassifier(min_samples_split=2, max_depth=5, random_state=1,class_weight='balanced')\n",
    "DT.fit(Xtrain,ytrain)\n",
    "pred = DT.predict(Xtest.toarray())\n",
    "F1score[name]= f1_score(ytest,pred)\n",
    "Acc[name] = accuracy_score(ytest,pred)\n",
    "confusion_mat[name] = confusion_matrix(ytest,pred)\n",
    "predictions[name]=pred\n",
    "print(name+': Accuracy=%1.3f, F1=%1.3f'%(Acc[name],F1score[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open(\"dt.dot\", 'w')\n",
    "dot_data = tree.export_graphviz(\n",
    "    DT, class_names=['0', '1'], filled=True, rounded=True, out_file=output_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8e35784da7b5309346b9948007e2c8e432cfca57e220859a198433798687959"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
